{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold  # Import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('/Users/sunnyli/Desktop/dataset_lm (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422 entries, 0 to 421\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Dependent Var        422 non-null    float64\n",
      " 1   Explanatory Var #1   422 non-null    float64\n",
      " 2   Explanatory Var #2   422 non-null    float64\n",
      " 3   Explanatory Var #3   422 non-null    int64  \n",
      " 4   Explanatory Var #4   422 non-null    float64\n",
      " 5   Explanatory Var #5   422 non-null    float64\n",
      " 6   Explanatory Var #6   422 non-null    float64\n",
      " 7   Explanatory Var #7   422 non-null    float64\n",
      " 8   Explanatory Var #8   422 non-null    int64  \n",
      " 9   Explanatory Var #9   422 non-null    float64\n",
      " 10  Explanatory Var #10  422 non-null    float64\n",
      " 11  Explanatory Var #11  422 non-null    float64\n",
      " 12  Explanatory Var #12  422 non-null    float64\n",
      " 13  Explanatory Var #13  422 non-null    int64  \n",
      " 14  Explanatory Var #14  422 non-null    float64\n",
      " 15  Explanatory Var #15  422 non-null    float64\n",
      "dtypes: float64(13), int64(3)\n",
      "memory usage: 52.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependent Var</th>\n",
       "      <th>Explanatory Var #1</th>\n",
       "      <th>Explanatory Var #2</th>\n",
       "      <th>Explanatory Var #3</th>\n",
       "      <th>Explanatory Var #4</th>\n",
       "      <th>Explanatory Var #5</th>\n",
       "      <th>Explanatory Var #6</th>\n",
       "      <th>Explanatory Var #7</th>\n",
       "      <th>Explanatory Var #8</th>\n",
       "      <th>Explanatory Var #9</th>\n",
       "      <th>Explanatory Var #10</th>\n",
       "      <th>Explanatory Var #11</th>\n",
       "      <th>Explanatory Var #12</th>\n",
       "      <th>Explanatory Var #13</th>\n",
       "      <th>Explanatory Var #14</th>\n",
       "      <th>Explanatory Var #15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.293458</td>\n",
       "      <td>13.698667</td>\n",
       "      <td>50.639873</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.568035</td>\n",
       "      <td>45.121911</td>\n",
       "      <td>11.412501</td>\n",
       "      <td>56.410757</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.281132</td>\n",
       "      <td>38.996909</td>\n",
       "      <td>-3.010548</td>\n",
       "      <td>49.195073</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.153143</td>\n",
       "      <td>46.919314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.473431</td>\n",
       "      <td>2.714725</td>\n",
       "      <td>65.845845</td>\n",
       "      <td>1</td>\n",
       "      <td>-25.105932</td>\n",
       "      <td>47.190213</td>\n",
       "      <td>10.080280</td>\n",
       "      <td>65.383107</td>\n",
       "      <td>3</td>\n",
       "      <td>-36.763585</td>\n",
       "      <td>51.654939</td>\n",
       "      <td>4.991111</td>\n",
       "      <td>45.591729</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.474403</td>\n",
       "      <td>53.383508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.195330</td>\n",
       "      <td>11.618072</td>\n",
       "      <td>65.072497</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.897464</td>\n",
       "      <td>52.163036</td>\n",
       "      <td>11.057301</td>\n",
       "      <td>82.812717</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.733547</td>\n",
       "      <td>48.913837</td>\n",
       "      <td>-2.457696</td>\n",
       "      <td>56.608806</td>\n",
       "      <td>0</td>\n",
       "      <td>-27.903299</td>\n",
       "      <td>48.515026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.074583</td>\n",
       "      <td>0.818623</td>\n",
       "      <td>45.408996</td>\n",
       "      <td>1</td>\n",
       "      <td>-18.316132</td>\n",
       "      <td>54.356714</td>\n",
       "      <td>5.029029</td>\n",
       "      <td>48.812471</td>\n",
       "      <td>1</td>\n",
       "      <td>-12.825591</td>\n",
       "      <td>45.851732</td>\n",
       "      <td>14.974177</td>\n",
       "      <td>47.362594</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.064411</td>\n",
       "      <td>55.266254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86.035569</td>\n",
       "      <td>9.077544</td>\n",
       "      <td>73.548021</td>\n",
       "      <td>0</td>\n",
       "      <td>-19.204165</td>\n",
       "      <td>47.186807</td>\n",
       "      <td>12.128134</td>\n",
       "      <td>62.520911</td>\n",
       "      <td>2</td>\n",
       "      <td>-13.804860</td>\n",
       "      <td>47.765904</td>\n",
       "      <td>9.593982</td>\n",
       "      <td>53.700562</td>\n",
       "      <td>0</td>\n",
       "      <td>-17.546302</td>\n",
       "      <td>48.150543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dependent Var  Explanatory Var #1  Explanatory Var #2  Explanatory Var #3   \n",
       "0      56.293458           13.698667           50.639873                   0  \\\n",
       "1      58.473431            2.714725           65.845845                   1   \n",
       "2      94.195330           11.618072           65.072497                   0   \n",
       "3      29.074583            0.818623           45.408996                   1   \n",
       "4      86.035569            9.077544           73.548021                   0   \n",
       "\n",
       "   Explanatory Var #4  Explanatory Var #5  Explanatory Var #6   \n",
       "0          -18.568035           45.121911           11.412501  \\\n",
       "1          -25.105932           47.190213           10.080280   \n",
       "2           -7.897464           52.163036           11.057301   \n",
       "3          -18.316132           54.356714            5.029029   \n",
       "4          -19.204165           47.186807           12.128134   \n",
       "\n",
       "   Explanatory Var #7  Explanatory Var #8  Explanatory Var #9   \n",
       "0           56.410757                   2          -12.281132  \\\n",
       "1           65.383107                   3          -36.763585   \n",
       "2           82.812717                   0          -15.733547   \n",
       "3           48.812471                   1          -12.825591   \n",
       "4           62.520911                   2          -13.804860   \n",
       "\n",
       "   Explanatory Var #10  Explanatory Var #11  Explanatory Var #12   \n",
       "0            38.996909            -3.010548            49.195073  \\\n",
       "1            51.654939             4.991111            45.591729   \n",
       "2            48.913837            -2.457696            56.608806   \n",
       "3            45.851732            14.974177            47.362594   \n",
       "4            47.765904             9.593982            53.700562   \n",
       "\n",
       "   Explanatory Var #13  Explanatory Var #14  Explanatory Var #15  \n",
       "0                    0           -21.153143            46.919314  \n",
       "1                    0            -6.474403            53.383508  \n",
       "2                    0           -27.903299            48.515026  \n",
       "3                    1           -10.064411            55.266254  \n",
       "4                    0           -17.546302            48.150543  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = 0, 5 # mean and standard deviation of normal distribution for the error term\n",
    "x = np.random.uniform(40,80,100)\n",
    "epsilon = np.random.normal(mu,sigma,100)\n",
    "y = 3 + 4*x + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Dependent Var']\n",
    "X = df[['Explanatory Var #1', 'Explanatory Var #2', 'Explanatory Var #3', 'Explanatory Var #4', 'Explanatory Var #5',\n",
    "          'Explanatory Var #6', 'Explanatory Var #7', 'Explanatory Var #8', 'Explanatory Var #9', 'Explanatory Var #10',\n",
    "          'Explanatory Var #11', 'Explanatory Var #12', 'Explanatory Var #13', 'Explanatory Var #14', 'Explanatory Var #15']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared (uncentered):</th>      <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>4.509e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 29 Oct 2023</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:23:03</td>     <th>  Log-Likelihood:    </th>          <td> -841.76</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th>          <td>   1714.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   407</td>      <th>  BIC:               </th>          <td>   1774.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th>  <td>    1.3078</td> <td>    0.013</td> <td>  102.159</td> <td> 0.000</td> <td>    1.283</td> <td>    1.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th>  <td>    1.7667</td> <td>    0.009</td> <td>  203.101</td> <td> 0.000</td> <td>    1.750</td> <td>    1.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th>  <td>    6.6083</td> <td>    0.177</td> <td>   37.232</td> <td> 0.000</td> <td>    6.259</td> <td>    6.957</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th>  <td>    2.0725</td> <td>    0.011</td> <td>  189.896</td> <td> 0.000</td> <td>    2.051</td> <td>    2.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th>  <td>   -0.7776</td> <td>    0.011</td> <td>  -68.372</td> <td> 0.000</td> <td>   -0.800</td> <td>   -0.755</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #6</th>  <td>    0.0124</td> <td>    0.008</td> <td>    1.595</td> <td> 0.111</td> <td>   -0.003</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #7</th>  <td>    0.0286</td> <td>    0.006</td> <td>    4.890</td> <td> 0.000</td> <td>    0.017</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #8</th>  <td>    0.3510</td> <td>    0.080</td> <td>    4.398</td> <td> 0.000</td> <td>    0.194</td> <td>    0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #9</th>  <td>   -0.0293</td> <td>    0.010</td> <td>   -2.838</td> <td> 0.005</td> <td>   -0.050</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #10</th> <td>    0.1292</td> <td>    0.011</td> <td>   11.409</td> <td> 0.000</td> <td>    0.107</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #11</th> <td>    0.0145</td> <td>    0.013</td> <td>    1.152</td> <td> 0.250</td> <td>   -0.010</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #12</th> <td>    0.0752</td> <td>    0.009</td> <td>    8.698</td> <td> 0.000</td> <td>    0.058</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #13</th> <td>    0.7414</td> <td>    0.177</td> <td>    4.198</td> <td> 0.000</td> <td>    0.394</td> <td>    1.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #14</th> <td>   -0.0218</td> <td>    0.011</td> <td>   -1.974</td> <td> 0.049</td> <td>   -0.043</td> <td>-8.61e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #15</th> <td>    0.1212</td> <td>    0.012</td> <td>   10.324</td> <td> 0.000</td> <td>    0.098</td> <td>    0.144</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.087</td> <th>  Durbin-Watson:     </th> <td>   1.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.957</td> <th>  Jarque-Bera (JB):  </th> <td>   0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.004</td> <th>  Prob(JB):          </th> <td>   0.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.897</td> <th>  Cond. No.          </th> <td>    287.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &  Dependent Var   & \\textbf{  R-squared (uncentered):}      &     0.999   \\\\\n",
       "\\textbf{Model:}               &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.999   \\\\\n",
       "\\textbf{Method:}              &  Least Squares   & \\textbf{  F-statistic:       }          & 4.509e+04   \\\\\n",
       "\\textbf{Date:}                & Sun, 29 Oct 2023 & \\textbf{  Prob (F-statistic):}          &     0.00    \\\\\n",
       "\\textbf{Time:}                &     20:23:03     & \\textbf{  Log-Likelihood:    }          &   -841.76   \\\\\n",
       "\\textbf{No. Observations:}    &         422      & \\textbf{  AIC:               }          &     1714.   \\\\\n",
       "\\textbf{Df Residuals:}        &         407      & \\textbf{  BIC:               }          &     1774.   \\\\\n",
       "\\textbf{Df Model:}            &          15      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Explanatory Var \\#1}  &       1.3078  &        0.013     &   102.159  &         0.000        &        1.283    &        1.333     \\\\\n",
       "\\textbf{Explanatory Var \\#2}  &       1.7667  &        0.009     &   203.101  &         0.000        &        1.750    &        1.784     \\\\\n",
       "\\textbf{Explanatory Var \\#3}  &       6.6083  &        0.177     &    37.232  &         0.000        &        6.259    &        6.957     \\\\\n",
       "\\textbf{Explanatory Var \\#4}  &       2.0725  &        0.011     &   189.896  &         0.000        &        2.051    &        2.094     \\\\\n",
       "\\textbf{Explanatory Var \\#5}  &      -0.7776  &        0.011     &   -68.372  &         0.000        &       -0.800    &       -0.755     \\\\\n",
       "\\textbf{Explanatory Var \\#6}  &       0.0124  &        0.008     &     1.595  &         0.111        &       -0.003    &        0.028     \\\\\n",
       "\\textbf{Explanatory Var \\#7}  &       0.0286  &        0.006     &     4.890  &         0.000        &        0.017    &        0.040     \\\\\n",
       "\\textbf{Explanatory Var \\#8}  &       0.3510  &        0.080     &     4.398  &         0.000        &        0.194    &        0.508     \\\\\n",
       "\\textbf{Explanatory Var \\#9}  &      -0.0293  &        0.010     &    -2.838  &         0.005        &       -0.050    &       -0.009     \\\\\n",
       "\\textbf{Explanatory Var \\#10} &       0.1292  &        0.011     &    11.409  &         0.000        &        0.107    &        0.152     \\\\\n",
       "\\textbf{Explanatory Var \\#11} &       0.0145  &        0.013     &     1.152  &         0.250        &       -0.010    &        0.039     \\\\\n",
       "\\textbf{Explanatory Var \\#12} &       0.0752  &        0.009     &     8.698  &         0.000        &        0.058    &        0.092     \\\\\n",
       "\\textbf{Explanatory Var \\#13} &       0.7414  &        0.177     &     4.198  &         0.000        &        0.394    &        1.089     \\\\\n",
       "\\textbf{Explanatory Var \\#14} &      -0.0218  &        0.011     &    -1.974  &         0.049        &       -0.043    &    -8.61e-05     \\\\\n",
       "\\textbf{Explanatory Var \\#15} &       0.1212  &        0.012     &    10.324  &         0.000        &        0.098    &        0.144     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.087 & \\textbf{  Durbin-Watson:     } &    1.875  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.957 & \\textbf{  Jarque-Bera (JB):  } &    0.188  \\\\\n",
       "\\textbf{Skew:}          & -0.004 & \\textbf{  Prob(JB):          } &    0.910  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.897 & \\textbf{  Cond. No.          } &     287.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared (uncentered):                   0.999\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.999\n",
       "Method:                 Least Squares   F-statistic:                          4.509e+04\n",
       "Date:                Sun, 29 Oct 2023   Prob (F-statistic):                        0.00\n",
       "Time:                        20:23:03   Log-Likelihood:                         -841.76\n",
       "No. Observations:                 422   AIC:                                      1714.\n",
       "Df Residuals:                     407   BIC:                                      1774.\n",
       "Df Model:                          15                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "Explanatory Var #1      1.3078      0.013    102.159      0.000       1.283       1.333\n",
       "Explanatory Var #2      1.7667      0.009    203.101      0.000       1.750       1.784\n",
       "Explanatory Var #3      6.6083      0.177     37.232      0.000       6.259       6.957\n",
       "Explanatory Var #4      2.0725      0.011    189.896      0.000       2.051       2.094\n",
       "Explanatory Var #5     -0.7776      0.011    -68.372      0.000      -0.800      -0.755\n",
       "Explanatory Var #6      0.0124      0.008      1.595      0.111      -0.003       0.028\n",
       "Explanatory Var #7      0.0286      0.006      4.890      0.000       0.017       0.040\n",
       "Explanatory Var #8      0.3510      0.080      4.398      0.000       0.194       0.508\n",
       "Explanatory Var #9     -0.0293      0.010     -2.838      0.005      -0.050      -0.009\n",
       "Explanatory Var #10     0.1292      0.011     11.409      0.000       0.107       0.152\n",
       "Explanatory Var #11     0.0145      0.013      1.152      0.250      -0.010       0.039\n",
       "Explanatory Var #12     0.0752      0.009      8.698      0.000       0.058       0.092\n",
       "Explanatory Var #13     0.7414      0.177      4.198      0.000       0.394       1.089\n",
       "Explanatory Var #14    -0.0218      0.011     -1.974      0.049      -0.043   -8.61e-05\n",
       "Explanatory Var #15     0.1212      0.012     10.324      0.000       0.098       0.144\n",
       "==============================================================================\n",
       "Omnibus:                        0.087   Durbin-Watson:                   1.875\n",
       "Prob(Omnibus):                  0.957   Jarque-Bera (JB):                0.188\n",
       "Skew:                          -0.004   Prob(JB):                        0.910\n",
       "Kurtosis:                       2.897   Cond. No.                         287.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reg = sm.OLS(y,X).fit()\n",
    "model_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared:         </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>7.593e+30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 29 Oct 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:23:03</td>     <th>  Log-Likelihood:    </th>  <td>  12339.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th> <td>-2.465e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   406</td>      <th>  BIC:               </th> <td>-2.458e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>   32.0000</td> <td> 4.32e-14</td> <td>  7.4e+14</td> <td> 0.000</td> <td>   32.000</td> <td>   32.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th>  <td>    1.3000</td> <td> 3.49e-16</td> <td> 3.72e+15</td> <td> 0.000</td> <td>    1.300</td> <td>    1.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th>  <td>    1.7000</td> <td> 2.54e-16</td> <td>  6.7e+15</td> <td> 0.000</td> <td>    1.700</td> <td>    1.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th>  <td>    6.2000</td> <td> 4.87e-15</td> <td> 1.27e+15</td> <td> 0.000</td> <td>    6.200</td> <td>    6.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th>  <td>    2.1000</td> <td>    3e-16</td> <td>    7e+15</td> <td> 0.000</td> <td>    2.100</td> <td>    2.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th>  <td>   -0.9000</td> <td> 3.51e-16</td> <td>-2.56e+15</td> <td> 0.000</td> <td>   -0.900</td> <td>   -0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #6</th>  <td>-3.842e-16</td> <td> 2.12e-16</td> <td>   -1.812</td> <td> 0.071</td> <td>-8.01e-16</td> <td> 3.27e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #7</th>  <td>-9.626e-16</td> <td> 1.64e-16</td> <td>   -5.876</td> <td> 0.000</td> <td>-1.28e-15</td> <td>-6.41e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #8</th>  <td>-2.789e-15</td> <td> 2.23e-15</td> <td>   -1.253</td> <td> 0.211</td> <td>-7.17e-15</td> <td> 1.59e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #9</th>  <td> 7.033e-16</td> <td> 2.85e-16</td> <td>    2.471</td> <td> 0.014</td> <td> 1.44e-16</td> <td> 1.26e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #10</th> <td>-5.371e-16</td> <td> 3.55e-16</td> <td>   -1.514</td> <td> 0.131</td> <td>-1.23e-15</td> <td>  1.6e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #11</th> <td>-1.433e-15</td> <td> 3.43e-16</td> <td>   -4.178</td> <td> 0.000</td> <td>-2.11e-15</td> <td>-7.59e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #12</th> <td> 1.064e-15</td> <td> 2.57e-16</td> <td>    4.146</td> <td> 0.000</td> <td>  5.6e-16</td> <td> 1.57e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #13</th> <td>-1.977e-14</td> <td> 4.92e-15</td> <td>   -4.020</td> <td> 0.000</td> <td>-2.94e-14</td> <td>-1.01e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #14</th> <td>-5.991e-16</td> <td> 3.02e-16</td> <td>   -1.985</td> <td> 0.048</td> <td>-1.19e-15</td> <td>-5.64e-18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #15</th> <td>-3.694e-15</td> <td>  3.6e-16</td> <td>  -10.274</td> <td> 0.000</td> <td> -4.4e-15</td> <td>-2.99e-15</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.606</td> <th>  Durbin-Watson:     </th> <td>   1.878</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.448</td> <th>  Jarque-Bera (JB):  </th> <td>   1.555</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.149</td> <th>  Prob(JB):          </th> <td>   0.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.990</td> <th>  Cond. No.          </th> <td>2.55e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.55e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &  Dependent Var   & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}               &       OLS        & \\textbf{  Adj. R-squared:    } &     1.000   \\\\\n",
       "\\textbf{Method:}              &  Least Squares   & \\textbf{  F-statistic:       } & 7.593e+30   \\\\\n",
       "\\textbf{Date:}                & Sun, 29 Oct 2023 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                &     20:23:03     & \\textbf{  Log-Likelihood:    } &    12339.   \\\\\n",
       "\\textbf{No. Observations:}    &         422      & \\textbf{  AIC:               } & -2.465e+04  \\\\\n",
       "\\textbf{Df Residuals:}        &         406      & \\textbf{  BIC:               } & -2.458e+04  \\\\\n",
       "\\textbf{Df Model:}            &          15      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                &      32.0000  &     4.32e-14     &   7.4e+14  &         0.000        &       32.000    &       32.000     \\\\\n",
       "\\textbf{Explanatory Var \\#1}  &       1.3000  &     3.49e-16     &  3.72e+15  &         0.000        &        1.300    &        1.300     \\\\\n",
       "\\textbf{Explanatory Var \\#2}  &       1.7000  &     2.54e-16     &   6.7e+15  &         0.000        &        1.700    &        1.700     \\\\\n",
       "\\textbf{Explanatory Var \\#3}  &       6.2000  &     4.87e-15     &  1.27e+15  &         0.000        &        6.200    &        6.200     \\\\\n",
       "\\textbf{Explanatory Var \\#4}  &       2.1000  &        3e-16     &     7e+15  &         0.000        &        2.100    &        2.100     \\\\\n",
       "\\textbf{Explanatory Var \\#5}  &      -0.9000  &     3.51e-16     & -2.56e+15  &         0.000        &       -0.900    &       -0.900     \\\\\n",
       "\\textbf{Explanatory Var \\#6}  &   -3.842e-16  &     2.12e-16     &    -1.812  &         0.071        &    -8.01e-16    &     3.27e-17     \\\\\n",
       "\\textbf{Explanatory Var \\#7}  &   -9.626e-16  &     1.64e-16     &    -5.876  &         0.000        &    -1.28e-15    &    -6.41e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#8}  &   -2.789e-15  &     2.23e-15     &    -1.253  &         0.211        &    -7.17e-15    &     1.59e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#9}  &    7.033e-16  &     2.85e-16     &     2.471  &         0.014        &     1.44e-16    &     1.26e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#10} &   -5.371e-16  &     3.55e-16     &    -1.514  &         0.131        &    -1.23e-15    &      1.6e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#11} &   -1.433e-15  &     3.43e-16     &    -4.178  &         0.000        &    -2.11e-15    &    -7.59e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#12} &    1.064e-15  &     2.57e-16     &     4.146  &         0.000        &      5.6e-16    &     1.57e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#13} &   -1.977e-14  &     4.92e-15     &    -4.020  &         0.000        &    -2.94e-14    &    -1.01e-14     \\\\\n",
       "\\textbf{Explanatory Var \\#14} &   -5.991e-16  &     3.02e-16     &    -1.985  &         0.048        &    -1.19e-15    &    -5.64e-18     \\\\\n",
       "\\textbf{Explanatory Var \\#15} &   -3.694e-15  &      3.6e-16     &   -10.274  &         0.000        &     -4.4e-15    &    -2.99e-15     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.606 & \\textbf{  Durbin-Watson:     } &    1.878  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.448 & \\textbf{  Jarque-Bera (JB):  } &    1.555  \\\\\n",
       "\\textbf{Skew:}          &  0.149 & \\textbf{  Prob(JB):          } &    0.460  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.990 & \\textbf{  Cond. No.          } & 2.55e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.55e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 7.593e+30\n",
       "Date:                Sun, 29 Oct 2023   Prob (F-statistic):               0.00\n",
       "Time:                        20:23:03   Log-Likelihood:                 12339.\n",
       "No. Observations:                 422   AIC:                        -2.465e+04\n",
       "Df Residuals:                     406   BIC:                        -2.458e+04\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                  32.0000   4.32e-14    7.4e+14      0.000      32.000      32.000\n",
       "Explanatory Var #1      1.3000   3.49e-16   3.72e+15      0.000       1.300       1.300\n",
       "Explanatory Var #2      1.7000   2.54e-16    6.7e+15      0.000       1.700       1.700\n",
       "Explanatory Var #3      6.2000   4.87e-15   1.27e+15      0.000       6.200       6.200\n",
       "Explanatory Var #4      2.1000      3e-16      7e+15      0.000       2.100       2.100\n",
       "Explanatory Var #5     -0.9000   3.51e-16  -2.56e+15      0.000      -0.900      -0.900\n",
       "Explanatory Var #6  -3.842e-16   2.12e-16     -1.812      0.071   -8.01e-16    3.27e-17\n",
       "Explanatory Var #7  -9.626e-16   1.64e-16     -5.876      0.000   -1.28e-15   -6.41e-16\n",
       "Explanatory Var #8  -2.789e-15   2.23e-15     -1.253      0.211   -7.17e-15    1.59e-15\n",
       "Explanatory Var #9   7.033e-16   2.85e-16      2.471      0.014    1.44e-16    1.26e-15\n",
       "Explanatory Var #10 -5.371e-16   3.55e-16     -1.514      0.131   -1.23e-15     1.6e-16\n",
       "Explanatory Var #11 -1.433e-15   3.43e-16     -4.178      0.000   -2.11e-15   -7.59e-16\n",
       "Explanatory Var #12  1.064e-15   2.57e-16      4.146      0.000     5.6e-16    1.57e-15\n",
       "Explanatory Var #13 -1.977e-14   4.92e-15     -4.020      0.000   -2.94e-14   -1.01e-14\n",
       "Explanatory Var #14 -5.991e-16   3.02e-16     -1.985      0.048   -1.19e-15   -5.64e-18\n",
       "Explanatory Var #15 -3.694e-15    3.6e-16    -10.274      0.000    -4.4e-15   -2.99e-15\n",
       "==============================================================================\n",
       "Omnibus:                        1.606   Durbin-Watson:                   1.878\n",
       "Prob(Omnibus):                  0.448   Jarque-Bera (JB):                1.555\n",
       "Skew:                           0.149   Prob(JB):                        0.460\n",
       "Kurtosis:                       2.990   Cond. No.                     2.55e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.55e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_updated = sm.add_constant(X)\n",
    "model_updated = sm.OLS(y,x_updated).fit()\n",
    "model_updated.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon[0] = np.random.normal(mu,sigma,1)\n",
    "for i in range(0,99):\n",
    "    epsilon[i+1]=0.4*epsilon[i]+0.6*np.random.normal(mu,sigma,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 3 + 4*x + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.996</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.996</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>2.563e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 29 Oct 2023</td> <th>  Prob (F-statistic):</th> <td>2.34e-120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:23:03</td>     <th>  Log-Likelihood:    </th> <td> -248.42</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   500.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   506.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.8109</td> <td>    1.527</td> <td>    0.531</td> <td> 0.597</td> <td>   -2.219</td> <td>    3.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    4.0193</td> <td>    0.025</td> <td>  160.085</td> <td> 0.000</td> <td>    3.969</td> <td>    4.069</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.460</td> <th>  Durbin-Watson:     </th> <td>   1.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.482</td> <th>  Jarque-Bera (JB):  </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.058</td> <th>  Prob(JB):          </th> <td>   0.623</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.462</td> <th>  Cond. No.          </th> <td>    317.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.996   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.996   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } & 2.563e+04   \\\\\n",
       "\\textbf{Date:}             & Sun, 29 Oct 2023 & \\textbf{  Prob (F-statistic):} & 2.34e-120   \\\\\n",
       "\\textbf{Time:}             &     20:23:03     & \\textbf{  Log-Likelihood:    } &   -248.42   \\\\\n",
       "\\textbf{No. Observations:} &         100      & \\textbf{  AIC:               } &     500.8   \\\\\n",
       "\\textbf{Df Residuals:}     &          98      & \\textbf{  BIC:               } &     506.1   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       0.8109  &        1.527     &     0.531  &         0.597        &       -2.219    &        3.841     \\\\\n",
       "\\textbf{x1}    &       4.0193  &        0.025     &   160.085  &         0.000        &        3.969    &        4.069     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.460 & \\textbf{  Durbin-Watson:     } &    1.363  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.482 & \\textbf{  Jarque-Bera (JB):  } &    0.946  \\\\\n",
       "\\textbf{Skew:}          &  0.058 & \\textbf{  Prob(JB):          } &    0.623  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.462 & \\textbf{  Cond. No.          } &     317.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.996\n",
       "Model:                            OLS   Adj. R-squared:                  0.996\n",
       "Method:                 Least Squares   F-statistic:                 2.563e+04\n",
       "Date:                Sun, 29 Oct 2023   Prob (F-statistic):          2.34e-120\n",
       "Time:                        20:23:03   Log-Likelihood:                -248.42\n",
       "No. Observations:                 100   AIC:                             500.8\n",
       "Df Residuals:                      98   BIC:                             506.1\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.8109      1.527      0.531      0.597      -2.219       3.841\n",
       "x1             4.0193      0.025    160.085      0.000       3.969       4.069\n",
       "==============================================================================\n",
       "Omnibus:                        1.460   Durbin-Watson:                   1.363\n",
       "Prob(Omnibus):                  0.482   Jarque-Bera (JB):                0.946\n",
       "Skew:                           0.058   Prob(JB):                        0.623\n",
       "Kurtosis:                       3.462   Cond. No.                         317.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_updated = sm.add_constant(x)\n",
    "model_OLS = sm.OLS(y,x_updated).fit()\n",
    "model_OLS.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Errors: 2.9016437222086227\n",
      "Autocorrelation Lag 1: 0.3090552793959339\n",
      "Autocorrelation Lag 2: -0.06901228362507945\n",
      "Autocorrelation Lag 3: -0.07463199425300289\n"
     ]
    }
   ],
   "source": [
    "errors = model_OLS.resid\n",
    "\n",
    "error_std_dev = np.std(errors)\n",
    "\n",
    "# Calculate Autocorrelation for the first three lags manually\n",
    "autocorrelation_lag1 = np.corrcoef(errors[:-1], errors[1:])[0, 1]\n",
    "autocorrelation_lag2 = np.corrcoef(errors[:-2], errors[2:])[0, 1]\n",
    "autocorrelation_lag3 = np.corrcoef(errors[:-3], errors[3:])[0, 1]\n",
    "\n",
    "print(f\"Standard Deviation of Errors: {error_std_dev}\")\n",
    "print(f\"Autocorrelation Lag 1: {autocorrelation_lag1}\")\n",
    "print(f\"Autocorrelation Lag 2: {autocorrelation_lag2}\")\n",
    "print(f\"Autocorrelation Lag 3: {autocorrelation_lag3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            GLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.996\n",
      "Model:                            GLS   Adj. R-squared:                  0.996\n",
      "Method:                 Least Squares   F-statistic:                 2.563e+04\n",
      "Date:                Sun, 29 Oct 2023   Prob (F-statistic):          2.34e-120\n",
      "Time:                        20:23:03   Log-Likelihood:                -248.42\n",
      "No. Observations:                 100   AIC:                             500.8\n",
      "Df Residuals:                      98   BIC:                             506.1\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.8109      1.527      0.531      0.597      -2.219       3.841\n",
      "x1             4.0193      0.025    160.085      0.000       3.969       4.069\n",
      "==============================================================================\n",
      "Omnibus:                        1.460   Durbin-Watson:                   1.363\n",
      "Prob(Omnibus):                  0.482   Jarque-Bera (JB):                0.946\n",
      "Skew:                           0.058   Prob(JB):                        0.623\n",
      "Kurtosis:                       3.462   Cond. No.                         317.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_OLS.predict(x_updated)  # Predicted values from the OLS model\n",
    "error_values = y - y_pred  # Calculate the residuals\n",
    "\n",
    "# Compute standard deviation of errors\n",
    "std_deviation = error_values.std()\n",
    "\n",
    "# Create a 1D array of length 422 with a constant value (standard deviation)\n",
    "sigma = np.full(len(y), std_deviation)\n",
    "\n",
    "# Fit a GLS model using the OLS results and the calculated error values\n",
    "model_gls = sm.GLS(y, x_updated, sigma=sigma)\n",
    "results_gls = model_gls.fit()\n",
    "\n",
    "# Display the summary table for the GLS model\n",
    "print(results_gls.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((211, 15), (211, 15))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Dependent Var', axis=1)  # Explanatory variables\n",
    "y = df['Dependent Var']  # Dependent variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has been split into training and test sets.\n",
    " Both sets contain 211 samples each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.26972628,  1.68394638,  2.02626245,  2.08756512, -0.91746375,\n",
       "       -0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.01314162,  0.        , -0.        ,  0.        , -0.03617731])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the Lasso regression model with alpha=1\n",
    "lasso_model = Lasso(alpha=1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Extracting the coefficients\n",
    "coefficients = lasso_model.coef_\n",
    "\n",
    "coefficients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the coefficients are exactly zero, which is a characteristic of Lasso regression. \n",
    "\n",
    "This indicates that Lasso has performed feature selection by assigning 0 weights to certain explanatory variables, effectively excluding them from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.432190198291582"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting using the Lasso model on the test set\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "\n",
    "# Calculating MAPE\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01, 0.04429881163346635)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a range of alpha values for grid search\n",
    "alpha_values = np.linspace(0.01, 10, 1000)\n",
    "\n",
    "# Lists to store results\n",
    "alpha_results = []\n",
    "mape_results = []\n",
    "\n",
    "# Grid search over alpha values\n",
    "for alpha in alpha_values:\n",
    "    lasso_model = Lasso(alpha=alpha)\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    y_pred = lasso_model.predict(X_test)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    alpha_results.append(alpha)\n",
    "    mape_results.append(mape)\n",
    "\n",
    "# Find alpha that gives the minimum MAPE\n",
    "min_mape_idx = np.argmin(mape_results)\n",
    "optimal_alpha = alpha_results[min_mape_idx]\n",
    "optimal_mape = mape_results[min_mape_idx]\n",
    "\n",
    "optimal_alpha, optimal_mape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approximate value for α that minimizes the Mean Absolute Percentage Error (MAPE) on the test set is\n",
    "α=0.01. The corresponding MAPE for this α value is approximately 0.0443%.\n",
    "\n",
    "The approximate value for α that minimizes the Mean Absolute Percentage Error (MAPE) on the test set is α=0.01."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Month\": list(range(1, 26)),\n",
    "    \"Demand\": [100, 112, 107, 103, 91, 85, 84, 85, 79, 81, 134, 86, 99, 89, 111, 114, 118, 163, 193, 143, 144, 202, 158, 160, 144]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "advance_demand = [71, 30, 75, 64, 41, 51, 42, 51, 57, 49, 134, 52, 99, 56, 81, 79, 73, 163, 193, 99, 91, 202, 105, 101, 96]\n",
    "df[\"Advance_demand\"] = advance_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.iloc[:20]\n",
    "test_data = df.iloc[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 15.31%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Features and target variable\n",
    "X_train = train_data[[\"Month\", \"Advance_demand\"]]\n",
    "y_train = train_data[\"Demand\"]\n",
    "X_test = test_data[[\"Month\", \"Advance_demand\"]]\n",
    "y_test = test_data[\"Demand\"]\n",
    "\n",
    "# Create and fit the model\n",
    "alpha = 1.0  # You can adjust alpha based on your model performance\n",
    "model = Ridge(alpha=alpha)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Absolute Percentage Error (MAPE)\n",
    "mape = mean_absolute_error(y_test, y_pred) / y_test.mean() * 100\n",
    "\n",
    "print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 10.0\n",
      "MAPE on Test Data: 15.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Features and target variable\n",
    "X_train = train_data[[\"Month\", \"Advance_demand\"]]\n",
    "y_train = train_data[\"Demand\"]\n",
    "\n",
    "# Define a range of alpha values to test\n",
    "alpha_values = [0.01, 0.1, 1.0, 10.0]\n",
    "\n",
    "# Initialize variables to store the best alpha and the corresponding MAPE\n",
    "best_alpha = None\n",
    "best_mape = float('inf')\n",
    "\n",
    "# Iterate through alpha values\n",
    "for alpha in alpha_values:\n",
    "    # Create and fit the model with the current alpha\n",
    "    model = Ridge(alpha=alpha)\n",
    "    \n",
    "    # Perform cross-validation to estimate model performance\n",
    "    mape_scores = -cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=5)\n",
    "    \n",
    "    # Calculate the average MAPE score\n",
    "    average_mape = mape_scores.mean()\n",
    "    \n",
    "    # Check if this alpha provides a better model\n",
    "    if average_mape < best_mape:\n",
    "        best_alpha = alpha\n",
    "        best_mape = average_mape\n",
    "\n",
    "# Fit the final model with the best alpha\n",
    "final_model = Ridge(alpha=best_alpha)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "X_test = test_data[[\"Month\", \"Advance_demand\"]]\n",
    "y_test = test_data[\"Demand\"]\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Calculate MAPE on the test set\n",
    "mape = mean_absolute_error(y_test, y_pred) / y_test.mean() * 100\n",
    "\n",
    "print(f\"Best Alpha: {best_alpha}\")\n",
    "print(f\"MAPE on Test Data: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=10.0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=10.0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=10.0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "best_alpha = 10.0  \n",
    "final_model = Ridge(alpha=best_alpha)\n",
    "final_model.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE on Test Data: 15.81%\n"
     ]
    }
   ],
   "source": [
    "y_pred = final_model.predict(X_test) \n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "print(f\"MAPE on Test Data: {mape:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
